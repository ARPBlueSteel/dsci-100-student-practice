{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# DSCI 100 - Introduction to Data Science\n",
    "\n",
    "\n",
    "## Lecture 6 - Classification using K-Nearest Neighbours\n",
    "\n",
    "<center>\n",
    "    <img src = \"https://www.tidymodels.org/images/cover.png\" width=\"800\"/>\n",
    "    </center>\n",
    "Source: https://www.tidymodels.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Housekeeping\n",
    "\n",
    "**Quiz 1**\n",
    "- Quiz grading will take roughly 2 weeks\n",
    "\n",
    "**Projects**\n",
    "- TAs have been assigned to each of your groups (see `group_TAs` on Canvas)\n",
    "    - Summer: they will be assigned and you will know who they are on Thursday\n",
    "- Your `group_contract` will be due next Saturday!\n",
    "    - it's a group submission; only one team member needed to submit\n",
    "    - team evaluations are an important component of the project \n",
    "    - if you still have not been able to connect with a team member\n",
    "    - For Thursday/Next week:\n",
    "        1. send a message through Canvas\n",
    "        1. we have sent messaging about missing team members so hopefully you hear back but if not remember that you will have the opportunity to evaluate\n",
    "- Visit the `slides_group_project` item on Canvas to see some activities to get your group warmed up!\n",
    "- See the `group_project_proposal` to explore data sets for the project\n",
    "\n",
    "\n",
    "<!-- <img align=\"left\" src=\"https://media.giphy.com/media/3o7TKU8RvQuomFfUUU/giphy.gif\" width=\"500\" /> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reminder  \n",
    "\n",
    "Where are we? Where are we going?\n",
    "\n",
    "<center>\n",
    "    <img src = \"https://d33wubrfki0l68.cloudfront.net/571b056757d68e6df81a3e3853f54d3c76ad6efc/32d37/diagrams/data-science.png\" width=\"800\"/>\n",
    "    </center>\n",
    "\n",
    "*source: [R for Data Science](https://r4ds.had.co.nz/) by Grolemund & Wickham*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification\n",
    "\n",
    "Suppose we have past data of cancer tumour cell diagnosis labelled \"benign\" and \"malignant\".\n",
    "\n",
    "Do you think a new cell with Concavity = 4 and Perimeter = 2 would be malignant? How did you decide?\n",
    "\n",
    "<center><img src=\"https://datasciencebook.ca/_main_files/figure-html/05-knn-1-1.png\" width=\"600\"/></center> \n",
    "\n",
    "\n",
    "<!-- <center><img src=\"https://ubc-dsci.github.io/introduction-to-datascience/_main_files/figure-html/05-knn-4-1.png\" width=\"600\"/></center> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Do you think a new cell with Concavity = 3.3 and Perimeter = 0.2 would be malignant? How did you decide?\n",
    "\n",
    "<center><img src=\"https://ubc-dsci.github.io/introduction-to-datascience/_main_files/figure-html/05-knn-4-1.png\" width=\"600\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## What kind of data analysis question is this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Types of questions: \n",
    "- descriptive\n",
    "- exploratory\n",
    "- **predictive**\n",
    "- inferential \n",
    "- causal \n",
    "- mechanistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## K-nearest neighbours classification\n",
    "\n",
    "*Predict the label / class for a new observation using the K closest points from our dataset.*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Compute the distance between the new observation and each observation in our *training set*<br><br>\n",
    "\n",
    "<center>\n",
    "$\\text{Distance} = \\sqrt{(x_{\\text{new}} - x_{\\text{train}})^2 + (y_{\\text{new}} - y_{\\text{train}})^2}$\n",
    "</center>\n",
    "\n",
    "<center>\n",
    "<img src=\"https://ubc-dsci.github.io/introduction-to-datascience/_main_files/figure-html/05-knn-4-1.png\" width=\"600\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- point is at perimeter= 0.2, concavity = 3.3 \n",
    "- Recall from your reading, the training dataset is the sample of data used to fit the model.\n",
    "- Suppose we have a set of data and we want to predict the class of a new observation \n",
    "- we want to calculate the distance between the new observation and the other points "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## K-nearest neighbours classification\n",
    "\n",
    "*Predict the label / class for a new observation using the K closest points from our dataset.*\n",
    "\n",
    "2. Sort the data in ascending order according to the distances\n",
    "3. Choose the top K rows as \"neighbours\"\n",
    "```\n",
    "## # A tibble: 5 x 5\n",
    "##        ID Perimeter Concavity Class dist_from_new\n",
    "##     <dbl>     <dbl>     <dbl> <fct>         <dbl>\n",
    "## 1   86409     0.241      2.65 B             0.881\n",
    "## 2  887181     0.750      2.87 M             0.980\n",
    "## 3  899667     0.623      2.54 M             1.14 \n",
    "## 4  907914     0.417      2.31 M             1.26 \n",
    "## 5 8710441    -1.16       4.04 B             1.28\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## K-nearest neighbours classification\n",
    "\n",
    "*Predict the label / class for a new observation using the K closest points from our dataset.*\n",
    "\n",
    "4. Classify the new observation based on majority vote.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://ubc-dsci.github.io/introduction-to-datascience/_main_files/figure-html/05-knn-5-1.png\" width=\"600\"/>\n",
    "</center>\n",
    "\n",
    "### What would the predicted class be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## We can go beyond 2 predictors\n",
    "\n",
    "For two observations $u, v$, each with $m$ variables (columns) labelled $1, \\dots, m$,\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "   $\\text{Distance} = \\sqrt{(u_1-v_1)^2 + (u_2-v_2)^2 + \\dots + (u_m - v_m)^2}$ \n",
    "</center>\n",
    "\n",
    "Aside from that, it's the same algorithm!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Standardizing Data\n",
    "<center><img src=\"img/scaling_example1.png\" width=\"400\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"img/scaling_example2.png\" width=\"400\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- When using K-nearest neighbour classification, the scale of each variable (i.e., its size and range of values) matters. e.g. Salary (10,000+) and Age (0-100)\n",
    "- Since the classifier predicts classes by identifying observations that are nearest to it, any variables that have a large scale will have a much larger effect than variables with a small scale.\n",
    "- But just because a variable has a large scale doesnâ€™t mean that it is more important for making accurate predictions. \n",
    "- For example, suppose you have a data set with two attributes, height (in feet) and weight (in pounds). \n",
    "\n",
    "distance1 = sqrt((202 - 200)^2 + (6 - 6)^2) = 2\n",
    "\n",
    "distance2 = sqrt((200 - 200)^2 + (8 - 6)^2) = 2\n",
    "\n",
    "Here if we calculate the distance we get 2 in both cases! A difference of 2 pounds is not that big, but a different in 2 feet is a lot. So how can we adjust for this? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Nonstandardized Data\n",
    "\n",
    "What if one variable is much larger than the other? \n",
    "\n",
    "<br>\n",
    "<center>\n",
    "<img src=\"img/nonstd.png\" width=\"800\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Nonstandardized Data vs Standardized Data\n",
    "\n",
    "What if one variable is much larger than the other? \n",
    "\n",
    "*Standardize:* shift and scale so that the average is 0 and the standard deviation is 1.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "<img src=\"https://ubc-dsci.github.io/introduction-to-datascience/_main_files/figure-html/05-scaling-plt-1.png\" width=\"1600\"/>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "\n",
    "- Standardization: when all variables in a data set have a mean (center) of 0 and a standard deviation (scale) of 1, we say that the data have been standardized.\n",
    "\n",
    "- In the plot with the original data above, its very clear that K-nearest neighbours would classify the red dot (new observation) as malignant. However, once we standardize the data, the diagnosis class labelling becomes less clear, and appears it would depend upon the choice of  \n",
    "K. \n",
    "- Thus, standardizing the data can change things in an important way when we are using predictive algorithms. As a rule of thumb, standardizing your data should be a part of the preprocessing you do before any predictive modelling / analysis.\n",
    "\n",
    "- In many other predictive models, the center of each variable (e.g., its mean) matters as well. For example, if we had a data set with a temperature variable measured in degrees Kelvin, and the same data set with temperature measured in degrees Celcius, the two variables would differ by a constant shift of 273 (even though they contain exactly the same information). Likewise in our hypothetical job classification example, we would likely see that the center of the salary variable is in the tens of thousands, while the center of the years of education variable is in the single digits. \n",
    "- Although this doesnâ€™t affect the K-nearest neighbour classification algorithm, this large shift can change the outcome of using many other predictive models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction to the `tidymodels` package in R\n",
    "\n",
    "Tidymodels handles computing distances, standardization, balancing, and prediction for us!\n",
    "\n",
    "0. Load the libraries and data we need (new: `tidymodels`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "options(repr.matrix.max.rows = 6)\n",
    "\n",
    "cancer <- read_csv(\"data/clean-wdbc.data.csv\") %>%\n",
    "              mutate(Class = as_factor(Class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- tidymodels? consistency.\n",
    "- R open source -- made by different people and using different principles, everything has a slightly different interface, and trying to keep everything in line can be frustrating\n",
    "- aim: uniform interface for variety of models that exist in R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction to the `tidymodels` package in R\n",
    "\n",
    "0b. Inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction to the `tidymodels` package in R\n",
    "\n",
    "`tidymodels` is a collection of packages:\n",
    "<center>\n",
    "    <img src = \"https://i0.wp.com/rviews.rstudio.com/post/2019-06-14-a-gentle-intro-to-tidymodels_files/figure-html/tidymodels.png?zoom=2&w=578&ssl=1\" width=\"800\"/>\n",
    "    </center>\n",
    "Source: https://www.r-bloggers.com/2019/06/a-gentle-introduction-to-tidymodels/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction to the `tidymodels` package in R\n",
    "\n",
    "In `tidymodels`, the `recipes` package is named after cooking terms.\n",
    " \n",
    "### 1. Make a `recipe` to specify the predictors/response and preprocess the data\n",
    "1. `recipe()`:  Main argument in the formula. \n",
    "\n",
    "Arguments: \n",
    "\n",
    "- formula\n",
    "- data\n",
    "    \n",
    "2. `prep()` & `bake()`: you can also `prep` and `bake` a recipe to see what the preprocessing does!\n",
    "\n",
    "- visit https://recipes.tidymodels.org/reference/index.html to see all the preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "wdbc_recipe <- recipe(Class ~ Perimeter + Concavity, data = cancer) %>%\n",
    "                  step_center(all_predictors()) %>%\n",
    "                  step_scale(all_predictors()) \n",
    "wdbc_recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```\n",
    "wdbc_recipe <- recipe(Class ~ Perimeter + Concavity, data=cancer) %>%\n",
    "                  step_center(all_predictors()) %>%\n",
    "                  step_scale(all_predictors()) \n",
    "wdbc_recipe           \n",
    "```\n",
    "\n",
    "- first argument \"Model formula\" \n",
    "- Left hand side of ~: \"response\" / thing we are trying to predict (can selectively remove, but another step) \n",
    "- Right hand side: whatever columns you want to use as predictors (could use a . to use everything as a predictor) \n",
    "- second argument: data frame \n",
    "- pre-processing steps to standardize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "`prep()` and `bake`?\n",
    "\n",
    "- preprocessing recipe `wdbc_recipe` has been defined but no values have been estimated\n",
    "\n",
    "- The `prep()` function computes everything so that the preprocessing steps can be executed\n",
    "\n",
    "- The `bake()` function takes a recipe and applies it to data and returns data\n",
    "\n",
    "- If you want to extract the pre-processed dataset: you can `prep()` and `bake()` but extracting the pre-processed data isnâ€™t necessary for the pipeline, since this will be done under the hood when the model is fit\n",
    "\n",
    "- will be covered more next week "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction to the `tidymodels` package in R\n",
    "\n",
    "### 2. Build a model specification (`model_spec`) to specify the model and training algorithm\n",
    "\n",
    "1. **model type**: kind of model you want to fit\n",
    "\n",
    "2. **arguments**: model parameter values\n",
    "\n",
    "3. **engine**: underlying package the model should come from \n",
    "\n",
    "4. **mode**: type of prediction (some packages can do both classification and regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "wdbc_model <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 3) %>%\n",
    "       set_engine(\"kknn\") %>%\n",
    "       set_mode(\"classification\")\n",
    "\n",
    "wdbc_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```\n",
    "wdbc_model <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 3) %>%\n",
    "       set_engine(\"kknn\") %>%\n",
    "       set_mode(\"classification\")\n",
    "\n",
    "wdbc_model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- container for information about a model that will be fit\n",
    "- intended to be functionally independent of the data. model specification does not interact with the data \n",
    "- most R functions immediately evaluate their arguments. `parsnip` model functions do not \n",
    "- save the argument expressions to be evaluated later when `fit()` called with the actual data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction to the `tidymodels` package in R\n",
    "\n",
    "### 3. Put them together in a workflow and then `fit` it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdbc_workflow <- workflow() %>%\n",
    "                    add_recipe(wdbc_recipe) %>%\n",
    "                    add_model(wdbc_model)\n",
    "wdbc_fit <- wdbc_workflow %>%\n",
    "                fit(data=cancer)\n",
    "wdbc_workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- We may want to use our recipe across several steps as we train and test our model. To simplify this process, we can use a model workflow, which pairs a model and recipe together. \n",
    "- single function that can be used to prepare the recipe and train the model from the resulting predictors\n",
    "- `wdbc_workflow` -- still havenâ€™t yet implemented the pre-processing steps in the recipe nor fit the model. just the framework.\n",
    "- `wdbc_fit`: now the recipe and model frameworks are actually implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction to the `tidymodels` package in R\n",
    "\n",
    "### 4. Predict a new class label using `predict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "new_obs <- tibble(Perimeter = 0.2, Concavity = 3.3)\n",
    "predict(wdbc_fit, new_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"https://ubc-dsci.github.io/introduction-to-datascience/_main_files/figure-html/05-knn-5-1.png\" width = \"600\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- `predict()` applies the recipe to the new data, then passes them to the fitted model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Go forth and ... model?\n",
    "\n",
    "<br>\n",
    "<img align=\"left\" src=\"https://i.imgflip.com/2q2nlu.jpg\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What did we learn today? \n",
    "- \n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Class challenge\n",
    "\n",
    "Suppose we have a new observation in the `iris` dataset, with \n",
    "\n",
    "- petal length = 5\n",
    "- petal width = 0.6\n",
    "\n",
    "In your groups, discuss the following questions:\n",
    "- Create a plot to visualize the relationship between the predictors/features. Based on your plot, how would you classify this observation based on $k=3$ nearest neighbours?\n",
    "- Do you think we need to scale the data? Why or why not? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "```\n",
    "head(iris)\n",
    "options(repr.plot.width = 6, repr.plot.height = 3)\n",
    "ggplot(iris, aes(x = Petal.Length, y = Petal.Width, color = Species)) +\n",
    "    geom_point() + \n",
    "    labs( x= \"Petal Length (cm)\", y = \"Petal Width (cm)\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  },
  "rise": {
   "transition": "fade"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
