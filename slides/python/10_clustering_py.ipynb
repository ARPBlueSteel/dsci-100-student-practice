{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## DSCI 100 - Introduction to Data Science\n",
    "\n",
    "\n",
    "### Lecture 10 - Clustering\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/Cluster-2.svg/1920px-Cluster-2.svg.png\" width = 700>\n",
    "\n",
    "Image: https://commons.wikimedia.org/w/index.php?curid=9442336"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Housekeeping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Supervised Learning vs Unsupervised Learning \n",
    "\n",
    "- **Supervised learning**: We are given data that are **labelled** with a predictive target (e.g. category or numerical value) and we will use this data to make predictions for future data.\n",
    "    - classification: given tumour image, predict *malignant* or *benign* (category)\n",
    "    - regression: given age, weight, and sex, predict *marathon race time* (numerical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Unsupervised learning**: We are given **unlabelled** data, and the task is to find structure or patterns in the data\n",
    "\n",
    "<img src=\"https://datasciencebook.ca/_main_files/figure-html/10-toy-example-plot-1.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Clustering\n",
    "- **Clustering** is the unsupervised learning task of separating data into groups by similarity\n",
    "- Useful for exploratory analysis, developing new questions, and subgrouping to improve predictive models\n",
    "\n",
    "<img src=\"https://datasciencebook.ca/_main_files/figure-html/10-toy-example-clustering-1.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Examples  \n",
    "\n",
    "Clustering similar movies (to suggest movies you are likely to enjoy based on watching history)\n",
    "<img src=\"img/netflix.png\" width=\"800\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Clustering related products or customers (to advertise products you are likely to buy based on order history)   \n",
    "<img src=\"img/amazon.png\" width=\"800\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Which ones are clustering problems?\n",
    "\n",
    "1. Predict the score a student will get on the MCAT exam based on their past grades, the school they attended, and study habits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "\n",
    "2. Determine if there are patterns in the past grades, the school they attended, and self-reported study habits of students who take the MCAT, LSAT, and DAT exams.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "3. Separate photos into groups based on the labeled location of where the photo was taken\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "4. Separate photos into 5 distinct piles based on what is in the the photo images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## K-Means clustering algorithm\n",
    "\n",
    "K-Means is an algorithm for separating data into K clusters (*Illustrations by Allison Horst @allison_horst*)\n",
    "<img src=\"https://raw.githubusercontent.com/allisonhorst/stats-illustrations/main/other-stats-artwork/kmeans_1.jpg\" width=1100>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = https://raw.githubusercontent.com/allisonhorst/stats-illustrations/master/other-stats-artwork/kmeans_2.jpg width=1500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/allisonhorst/stats-illustrations/master/other-stats-artwork/kmeans_3.jpg\" width=1500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/allisonhorst/stats-illustrations/master/other-stats-artwork/kmeans_4.jpg\" width=1500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/allisonhorst/stats-illustrations/master/other-stats-artwork/kmeans_5.jpg\" width=1500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/allisonhorst/stats-illustrations/master/other-stats-artwork/kmeans_6.jpg\" width=1500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/allisonhorst/stats-illustrations/master/other-stats-artwork/kmeans_7.jpg\" width=1500> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/allisonhorst/stats-illustrations/master/other-stats-artwork/kmeans_8.jpg\" width=1500> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/allisonhorst/stats-illustrations/master/other-stats-artwork/kmeans_9.jpg\" width=1500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/allisonhorst/stats-illustrations/master/other-stats-artwork/kmeans_10.jpg\" width=1500> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = \"https://raw.githubusercontent.com/allisonhorst/stats-illustrations/master/other-stats-artwork/kmeans_11.jpg\" width=1500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = \"https://raw.githubusercontent.com/allisonhorst/stats-illustrations/master/other-stats-artwork/kmeans_12.jpg\" width=1500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## K-Means clustering summary\n",
    "\n",
    "1. **Choose K:** number of clusters to group the observations\n",
    "2. **Initialize:** assign data to K clusters randomly\n",
    "3. **Iterate:**\n",
    "    1. **Update Center:** calculate average coordinates of each cluster\n",
    "    2. **Update Label:** re-assign the data to the closest cluster center \n",
    "    3. **Check:** If no labels changed, terminate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Choosing K\n",
    "\n",
    "What value of K would *you* pick in this penguins data example? Why?\n",
    "\n",
    "<img src=\"https://datasciencebook.ca/_main_files/figure-html/10-toy-example-plot-1.png\" width=800> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Choosing K\n",
    "\n",
    "- K too small misses the clusters entirely whereas K too large \"subdivides\" the clusters\n",
    "- K = 3 looks just right; captures clusters, does not subdivide\n",
    "\n",
    "<img src=\"https://datasciencebook.ca/_main_files/figure-html/10-toy-kmeans-vary-k-1.png\" width=800>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is a \"good\" cluster?\n",
    "\n",
    "<img src=\"https://datasciencebook.ca/_main_files/figure-html/10-toy-example-clus1-center-1.png\" width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is a \"good\" cluster?\n",
    "\n",
    "<img src=\"https://datasciencebook.ca/_main_files/figure-html/10-toy-example-clus1-dists-1.png\" width=700>\n",
    "\n",
    "A good cluster of data is \"tightly packed\" around its centroid, i.e., has a small **within-cluster sum-of-squared-distances (WSSD)**.\n",
    "\n",
    "WSSD = Add up the squared **distance** between each **<font color=\"steelblue\">point</font>** and the **<font color=\"coral\">center/mean</font>** of the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is a \"good\" cluster?\n",
    "\n",
    "More than one cluster: add the WSSD for each cluster to get the **total WSSD!**\n",
    "\n",
    "<img src=\"https://datasciencebook.ca/_main_files/figure-html/10-toy-example-all-clus-dists-1.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Choosing K\n",
    "\n",
    "- If **K is too small**, the centers are bad representatives of the clusters, and **total WSSD is high**\n",
    "- If **K is too large**, the clusters get \"subdivided\", leading to a **slow decrease in total WSSD**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Pick K where the \"elbow\" occurs!** (if there is no obvious elbow, the data may not be very strongly clustered)\n",
    "\n",
    "<img src=\"https://datasciencebook.ca/_main_files/figure-html/10-toy-kmeans-elbow-1.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random Initialization\n",
    "\n",
    "- We can be unlucky with the random starting location of the centroids (http://shabal.in/visuals/kmeans/1.html)\n",
    "\n",
    "<img src=\"https://shabal.in/visuals/kmeans/data.gif\" width=1000>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random Initialization\n",
    "\n",
    "- **Unlucky** starting location of the centroids\n",
    "\n",
    "<img src=\"https://shabal.in/visuals/kmeans/left.gif\" width=1000>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random Initialization\n",
    "\n",
    "- **Lucky** starting location of the centroids\n",
    "\n",
    "<img src=\"https://shabal.in/visuals/kmeans/random.gif\" width=1000>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random Initialization\n",
    "\n",
    "- K-means is an *iterative* algorithm, unlike our past K-NN and linear classification/regression models\n",
    "- It will find different final clusterings depending on initialization\n",
    "- Use `random_state` and the `n_init` argument in scikit learns's implementation of the algorithm.\n",
    "\n",
    "`KMeans(n_clusters, random_state, **n_init**, ...)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## K-means pros and cons\n",
    "\n",
    "### Advantages\n",
    "- Easy to implement and interpret\n",
    "- Computationally more efficient than other clustering algorithms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Disadvantages\n",
    "- Need to specify K\n",
    "- Dependent on initialization\n",
    "- Sensitive to scale of features (need to normalize/standardize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Time to see if there is a pattern in your worksheet data!\n",
    "\n",
    "<img src=\"https://blog.revolutionanalytics.com/downloads/DataSaurus%20Dozen.gif\" width=900>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "rise": {
   "transition": "fade"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
